[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PHCM9795: Foundations of Biostatistics",
    "section": "",
    "text": "Course introduction\nWelcome to PHCM9795 Foundations of Biostatistics.\nThis introductory course in biostatistics aims to provide students with core biostatistical skills to analyse and present quantitative data from different study types. These are essential skills required in your degree and throughout your career.\nWe hope you enjoy the course and will value your feedback and comment throughout the course."
  },
  {
    "objectID": "index.html#course-information",
    "href": "index.html#course-information",
    "title": "PHCM9795: Foundations of Biostatistics",
    "section": "Course information",
    "text": "Course information\nBiostatistics is a foundational discipline needed for the analysis and interpretation of quantitative information and its application to population health policy and practice.\nThis course is central to becoming a population health practitioner as the concepts and techniques developed in the course are fundamental to your studies and practice in population health. In this course you will develop an understanding of, and skills in, the core concepts of biostatistics that are necessary for analysis and interpretation of population health data and health literature.\nIn designing this course, we provide a learning sequence that will allow you to obtain the required graduate capabilities identified for your program. This course is taught with an emphasis on formulating a hypothesis and quantifying the evidence in relation to a specific research question. You will have the opportunity to analyse data from different study types commonly seen in population health research.\nThe course will allow those of you who have covered some of this material in your undergraduate and other professional education to consolidate your knowledge and skills. Students exposed to biostatistics for the first time may find the course challenging at times. Based on student feedback, the key to success in this course is to devote time to it every week. We recommend that you spend an average of 10-15 hours per week on the course, including the time spent reading the course notes and readings, listening to lectures, and working through learning activities and completing your assessments. Please use the resources provided to assist you, including online support."
  },
  {
    "objectID": "index.html#units-of-credit",
    "href": "index.html#units-of-credit",
    "title": "PHCM9795: Foundations of Biostatistics",
    "section": "Units of credit",
    "text": "Units of credit\nThis course is a core course of the Master of Public Health, Master of Global Health and Master of Infectious Diseases Intelligence programs and associated dual degrees, comprising 6 units of credit towards the total required for completion of the study program. A value of 6 UOC requires a minimum of 150 hours work for the average student across the term."
  },
  {
    "objectID": "index.html#course-aim",
    "href": "index.html#course-aim",
    "title": "PHCM9795: Foundations of Biostatistics",
    "section": "Course aim",
    "text": "Course aim\nThis course aims to provide students with the core biostatistical skills to apply appropriate statistical techniques to analyse and present population health data."
  },
  {
    "objectID": "index.html#learning-outcomes",
    "href": "index.html#learning-outcomes",
    "title": "PHCM9795: Foundations of Biostatistics",
    "section": "Learning outcomes",
    "text": "Learning outcomes\nOn successful completion of this course, you will be able to:\n\nSummarise and visualise data using statistical software.\nDemonstrate an understanding of statistical inference by interpreting p-values and confidence intervals.\nApply appropriate statistical tests for different types of variables given a research question, and interpret computer output of these tests appropriately.\nDetermine the appropriate sample size when planning a research study.\nPresent and interpret statistical findings appropriate for a population health audience.\n\n\nChangelog\n2023-07-17\n[Changed]\n\nSection 7.9: Corrected screenshots to test difference in paired proportions in Stata.\n\n2023-07-13\n[Changed]\n\nSection 7.13: tidied up the R function used to calculate the 95% confidence interval for the difference in paired proportions.\n\n2023-07-12\n[Changed]\n\nWorked Example 6.2: removed “This z-statistic does not meet or exceed the critical value of 1.96 for a two tailed test” and re-framed this in terms of interpreting the P-value as calculated from software.\nWorked Example 7.1: corrected column headings for Nausea and No nausea\n\n2023-07-01\n[Changed]\n\nSection 4.2: Fixed typo: “The particular test statistic differs depending on the type of data being analyses analysed”\nSection 4.4: Fixed typo: “This is the situation described in scenario (c) of Figure Figure 4.1.”\nActivity 5.2: Added “or R” to the instruction “Use Stata to conduct an appropriate statistical test”\nActivity 5.3: Added “or R” to the instruction “Use Stata to conduct an appropriate statistical test”\nSection 6.3: Fixed formula for testing one sample proportion to: “\\(z = \\frac{(p_{sample} - p_{population})}{\\text{SE}(p_{population})}\\)”\nActivity 7.2: Added “or R” to the instruction “Using Stata, carry out the appropriate significance test”\n\n2023-07-01\n[Changed]\n\nRenamed “Readings” to “Optional readings”\nModule 4, Section 4.8: Corrected the sentence that describes Figure 4.4. “the shaded region for a one-tailed test would be doubled retained on one side of the distribution and eliminated from the other side of the distribution”.\nModule 9: Added titles to Tables 9.3 and 9.4.\nModule 9, Section 9.4: Corrected the level of evidence: “providing strong evidence of a difference in the median length of stay between the groups.”\nModule 9, Section 9.5.1. Corrected the text under Table 9.4: “The data shows … 10 people who have a negative positive difference.”\n\n2023-06-13\n[Changed]\n\nModule 3. Clarified Worked Example 3.1, and moved the example from Section 3.5.1 to Section 3.5.2.\nSection 3.6: Added Stata output for calculating a 95% confidence interval from individual data.\n\n2023-06-01\n[Changed]\n\nSection 1.14.3: RStudio preferences are now located at Edit &gt; Settings on MacOS, and Tools &gt; Global Options on Windows\nSection 1.14.7.2: Correct layout for commands to install packages (commands must be entered on separate lines)\nSection 1.15.2: Correct the name of the pbc data set to mod_01_pdc.rds\nActivity 2.3(b): Change the request to plot data on a Normal curve, not a standardised Normal curve\nActivity 5.3 and 5.4: added underscores to filenames"
  },
  {
    "objectID": "Revision-progress.html",
    "href": "Revision-progress.html",
    "title": "PHCM9795: Foundations of Biostatistics",
    "section": "",
    "text": "Module\nRevise main notes\nRevise Stata notes\nRevise R notes\nRevise activities\nRevise solutions\nReview\n\n\n\n\n1\n\n\n\n\n\n\n\n\n2\n\n\n\n\n\n\n\n\n3\nY\nY\nY\n\n\n\n\n\n4\nY\nY\nY\n\n\n\n\n\n5\n\n\n\n\n\n\n\n\n6\n\n\n\n\n\n\n\n\n7\n\n\n\n\n\n\n\n\n8\nY\nY\nY\n\n\n\n\n\n9\n\n\n\n\n\n\n\n\n10"
  },
  {
    "objectID": "06-proportions.html",
    "href": "06-proportions.html",
    "title": "2  Summary statistics for binary data",
    "section": "",
    "text": "Stata notes"
  },
  {
    "objectID": "06-proportions.html#learning-objectives",
    "href": "06-proportions.html#learning-objectives",
    "title": "2  Summary statistics for binary data",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of this module you will be able to:\n\nCompute and interpret 95% confidence intervals for proportions;\nConduct and interpret a significance test for a one-sample proportion;\nUse statistical software to compute 95% confidence intervals for a difference in proportions, a relative risk and an odds ratio."
  },
  {
    "objectID": "06-proportions.html#optional-readings",
    "href": "06-proportions.html#optional-readings",
    "title": "2  Summary statistics for binary data",
    "section": "Optional readings",
    "text": "Optional readings\nKirkwood and Sterne (2001); Chapter 16 [UNSW Library Link]\nBland (2015); Section 8.6, Section 13.7 [UNSW Library Link]\nAcock (2010); Section 7.5."
  },
  {
    "objectID": "06-proportions.html#introduction",
    "href": "06-proportions.html#introduction",
    "title": "2  Summary statistics for binary data",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\nIn Modules 4 and 5, we discussed methods used to test hypotheses when the data are continuous. In Modules 6 and 7, we will focus on hypothesis testing for binary categorical data.\nIn health research, we often collect information that can be put into two categories, e.g. male and female, disease present or disease absent etc. Binary categorical variables such as these are summarised using proportions."
  },
  {
    "objectID": "06-proportions.html#calculating-proportions-and-95-confidence-intervals",
    "href": "06-proportions.html#calculating-proportions-and-95-confidence-intervals",
    "title": "2  Summary statistics for binary data",
    "section": "2.2 Calculating proportions and 95% confidence intervals",
    "text": "2.2 Calculating proportions and 95% confidence intervals\n\n2.2.1 Calculating a proportion\nWe need two pieces of information to calculate a proportion: \\(n\\), the number of trials, and \\(k\\), the number of ‘successes’. Note that we use the term ‘success’ to describe the outcome of interest, recognising that a success may be a adverse outcome such as death or disease.\nThe following formula is used to calculate the proportion, \\(p\\):\n\\[ p = k / n \\]\nThe proportion, \\(p\\), is a number that lies between 0 and 1. Proportions and their confidence intervals can easily be converted to percentages by multiplying by 100 once computed.\nAs for all summary statistics, it is useful to compute the precision of the estimate as a 95% confidence interval (CI) to indicate the range of values in which are 95% confident that the true population value lies. In this module, we present two methods for computing a 95% confidence interval around a proportion.\n\n\n2.2.2 Calculating the 95% confidence interval of a proportion (Wald method)\nThe Wald method for calculating the 95% confidence interval is based on assuming that the proportion, \\(p\\), is Normally distributed. This assumption is reasonable if the sample is sufficiently large (for example, if \\(n&gt;30\\)) and if \\(n \\times (1-p)\\) and \\(n \\times p\\) are both larger than 5.\nThe Wald method for calculating a 95% confidence interval is given by:\n\\[\\text{95\\% CI} = p \\pm (1.96 \\times \\text{SE}(p))\\]\nwhere the standard error of a proportion is computed as:\n\\[\\text{SE}(p) = \\sqrt{\\frac{p \\times (1 - p)}{n}}\\]\n\n\n2.2.3 Worked Example 6.1\nIn a cross-sectional study of children living in a rural village, 47 children from a random sample of 215 children were found to have scabies. Here \\(n=215\\) and \\(k=47\\), so the proportion of children with scabies is estimated as:\n\\[ p = \\frac{47}{215} = 0.2186 \\]\nGiven the large sample size and the number of children with the rarer outcome is larger than 5, the Wald method is used to calculate the standard error of the proportion as:\n\\[{\\text{SE}\\left( p \\right) = \\sqrt{\\frac{0.2186 \\times (1 - 0.2186)}{215}}\n}{= 0.02819}\\]\nThen, the 95% confidence interval is estimated as:\n\\[\\text{95\\% CI} = 0.2816 \\pm 1.96 \\times 0.02819\\]\n\\[= 0.1634 \\text{ to } 0.2739\\]\nThe prevalence of scabies among children in the village is 21.9% (95% CI 16.3%, 27.4%). These values tell us that we are 95% confident that the true prevalence of scabies among children in the village is between 16.3% and 27.4%.\n\n\n2.2.4 Calculating the 95% confidence interval of a proportion (Wilson method)\nAnother method to calculate the confidence interval of a proportion is the Wilson (sometimes also called the ‘score’) method. We can use it in situations where it is not appropriate to use the normal approximation to the binomial distribution as described above i.e. if the sample size is small (\\(n &lt; 30\\)) or the number of subjects with the rarer outcome is 5 or fewer. This method much more difficult to implement by hand than the standard confidence interval, and so we will not discuss the hand calculation using the mathematical equation in this course. Instead, we use statistical software to do this (see the Stata or R notes for detail).\nWhen using software, our worked example provides a 95% confidence interval of the prevalence of scabies of 16.9% to 27.9%.\n\n\n2.2.5 Wald vs Wilson methods\nThe Wald method, which assumes that the underlying proportion follows a Normal distribution, is easy to calculate and follows the form of other confidence intervals. The Wilson method, which is difficult to calculate by hand, has nicer mathematical properties. There are also a number of other methods for calculating confidence intervals for proportions, but we do not discuss these in this course.\nA paper by Brown, Cai and DasGupta (Brown, Cai, and DasGupta (2001)) has compared the properties of the Wald and Wilson methods (among others) and concluded that the Wilson method is preferred over the Wald method. Therefore, we recommend the Wilson method be used to calculate 95% confidence intervals for a proportion."
  },
  {
    "objectID": "06-proportions.html#hypothesis-testing-for-one-sample-proportion",
    "href": "06-proportions.html#hypothesis-testing-for-one-sample-proportion",
    "title": "2  Summary statistics for binary data",
    "section": "2.3 Hypothesis testing for one sample proportion",
    "text": "2.3 Hypothesis testing for one sample proportion\nWe can carry out a hypothesis test to compare a sample proportion to a hypothesised proportion. In much the same way as a one sample t-test was used in Module 5 to test a sample mean against a hypothesised mean, we can perform a one-sample test to test a sample proportion against a hypothesised proportion. The significance test will provide a P-value to assess the evidence against the null hypothesis, while the 95% confidence interval will provide the range in which we are 95% confident that the true proportion lies.\nFor example, we can test the following null hypothesis:\nH0: sample proportion is not different from the hypothesised proportion\nMuch like constructing a 95% confidence interval, there are two main options when performing a hypothesis test on a single proportion: the first assumes that the proportion follows a Normal distribution, while the second relaxes this assumption.\n\n2.3.1 z-test for testing one sample proportion\nThe first step in the z-test is to calculate a z-statistic, which is then used to calculate a P-value. The z-statistic is calculated as the difference between the population proportion and the sample proportion divided by the standard error of the population proportion, i.e.\n\\[\nz = \\frac{(p_{sample} - p_{population})}{\\text{SE}(p_{population})}\n\\]\nThis z-statistic is then compared to the standard Normal distribution to calculate the P-value.\n\n\n2.3.2 Worked Example 6.2\nA national census in a country shows that 20% of the population are smokers. A survey of a community within the country that has received a public health anti-smoking intervention shows that 54 of 300 people sampled are smokers (18%). We can calculate a 95% confidence interval around this proportion using the Wilson method, which is calculated as 14.1% to 22.7%.\nThe researchers are interested in whether the proportion of smoking in this community is the same as the population prevalence of smoking of 20%. The null hypothesis can be written as: H0: the proportion of smokers in the community is 20% (the same as in the national census).\nWe can test this by calculating a z-statistic:\n\\[\n\\begin{aligned}\nz &= \\frac{(0.18 - 0.20)}{\\sqrt{\\frac{0.20 × (1 - 0.20)}{300}}} \\\\\n&= -0.87\n\\end{aligned}\n\\]\nThe P-value for the test above can be obtained from a Normal distribution table as \\(P = 2 × 0.192 = 0.38\\) (using Table A2.1 in the Appendix), or using the hand-calculator in Stata. This indicates that there is insufficient evidence to conclude that there is a difference between the proportion of smokers in the community and the country. This is consistent with our 95% confidence interval which crosses the null value of 20%.\n\n\n\n\n\n\n\n2.3.3 Binomial test for testing one sample proportion\nWe can use the binomial distribution to obtain an exact P-value for testing a single proportion. Historically, this was a time consuming process with much hand calculation. These days, statistical software performs the calculations quickly and efficiently, and is the preferred method.\n\n\n2.3.4 Worked example 6.3\nThe file mod06_smoking_status.csv contains the data for this example. In the data file, smokers are coded as 1 and non-smokers are coded as 0.\nIn Stata, we can use the prtest command to perform a z-test, or the bitest command to perform the exact binomial test. In R, we can use the prop.test function to perform a z-test, or the binom.test function to perform the exact binomial test.\nThe z-test provides a two-sided P-value of 0.39, while the binomial test gives a two-sided P-value of 0.43. Both tests provide little evidence against the hypothesis that the prevalence of smoking in the community is 20%."
  },
  {
    "objectID": "06-proportions.html#contingency-tables",
    "href": "06-proportions.html#contingency-tables",
    "title": "2  Summary statistics for binary data",
    "section": "2.4 Contingency tables",
    "text": "2.4 Contingency tables\nAs introduced in PHCM9794: Foundations of Epidemiology, 2-by-2 contingency tables can be used to examine associations between two binary variables, most commonly an exposure and an outcome. The traditional form of a 2-by-2 contigency table is given in Table 2.1.\n\n\n\n\nTable 2.1:  Traditional format for presenting a contingency table \n\n Outcome presentOutcome absentTotal\n\nExposure presentaba+b\n\nExposure absentcdc+d\n\nTotala+cb+dN\n\n\n\n\n\nNote for Stata users: It is important to note that Stata presents the exposure or intervention (present, absent) in the columns and the outcome or disease (present, absent) in the rows (e.g. Table 2.2). This is opposite to the way most epidemiological tables are presented, with exposure in rows and outcome in columns. Care must be taken when reading 2-by-2 tables generated from Stata.\n\n\n\n\nTable 2.2:  Stata format for presenting a contingency table \n\n Exposure presentExposure absentTotal\n\nOutcome presentaca+c\n\nOutcome absentbdb+d\n\nTotala+bc+dN\n\n\n\n\n\nWhen using a statistics program, it is recommended that the outcome and exposure variables are coded by assigning ‘absent’ as 0 and ‘present’ as 1, for example ‘No’ = 0 and ‘Yes’ = 1. This is needed for some of the commands to work (e.g. the epidemiology table commands). This coding ensures that measures of association, such as the odds ratio or relative risk, are computed correctly by Stata. While R does not require this coding to be followed, it is good practice nonetheless."
  },
  {
    "objectID": "06-proportions.html#a-brief-summary-of-epidemiological-study-types",
    "href": "06-proportions.html#a-brief-summary-of-epidemiological-study-types",
    "title": "2  Summary statistics for binary data",
    "section": "2.5 A brief summary of epidemiological study types",
    "text": "2.5 A brief summary of epidemiological study types\nIn this section, we wil present a very brief summary of three study types commonly used in population health research. This topic is covered in much more detail in PHCM9794: Foundations of Epidemiology, and more detail can be found in Chapter 4 of Essential Epidemiology (3rd or 4th edition) Webb, Bain and Page (Webb, Bain, and Page (2016)).\n\n2.5.1 Randomised controlled trial\nA randomised controlled trial addresses the research question: what is the effect of an intervention on an outcome. In the simplest form of a randomised controlled trial, a group of participants is randomly allocated to a group that receives the treatment of interest or to a control group that does not receive the treatment of interest. Participants are followed up over time, and the outcome is measured at the conclusion of the study.\n\n\n\n\n\nThe design of a randomised controlled trial [Figure 4.1, Essential Epidemiology]\n\n\n\n\n\n\n2.5.2 Cohort study\nA cohort study is an observational study that addresses the research question: what is the effect of an exposure on an outcome. This research question is similar to that studied in a randomised controlled trial, but the exposure is defined by the participants’ circumstances, and not manipulated by the researchers. In a cohort study, participants without the outcome of interest are enrolled, followed over time, and information on their exposure to a factor is measured (either at baseline or over time). At the conclusion of the study, information on the outcome is measured to identify new (incident) cases.\n\n\n\n\n\nThe design of a cohort study [Figure 4.2, Essential Epidemiology]\n\n\n\n\n\n\n2.5.3 Case control study\nWhile the randomised controlled trial and cohort study begin with a population without the outcome, a case-control study begins by assembling a group with the outcome of interest (cases), and a group without the outcome of interest (controls). The researchers then ask the cases and controls about their previous exposures.\n\n\n\n\n\nThe design of a case-control trial [Figure 4.3, Essential Epidemiology]\n\n\n\n\n\n\n2.5.4 Cross-sectional study\nIn a cross-sectional study, the exposure and the outcome are measured at the same time. While this results in a study that is relatively quick to conduct, it does not allow for any temporal relationships to be assessed.\n\n\n\n\n\nThe design of a cross-sectional study [Figure 4.4, Essential Epidemiology]"
  },
  {
    "objectID": "06-proportions.html#measures-of-effect-for-epidemiological-studies",
    "href": "06-proportions.html#measures-of-effect-for-epidemiological-studies",
    "title": "2  Summary statistics for binary data",
    "section": "2.6 Measures of effect for epidemiological studies",
    "text": "2.6 Measures of effect for epidemiological studies\nWe can calculate a relative measure of association between an exposure and an outcome as either a relative risk or odds ratio. The relative risk is a direct comparison of the risk in the exposed group with the risk in the non-exposed group, and can only be calculated for a cohort study (including a randomised controlled trial) or a cross-sectional study (where it is also called a prevalence ratio).\nFor cohort studies, randomised controlled trials and cross-section studies, we can calculate an absolute measure of association between an exposure and an outcome as a difference in proportions (also known as an attributable risk).\nFor case-control studies, as we sample participants based on their outcome, we can not estimate the risk of the outcome. Hence, calculating a relative risk or risk difference is inappropriate. Instead of calculating risks in a case-control study, we instead calculate odds, where the odds of an event are calculated as the number with the event divided by the number without the event.\n\n\n\n\nTable 2.3:  Contingency table for a case-control study \n\n CasesControlsTotal\n\nExposure presentaba+b\n\nExposure absentcdc+d\n\nTotala+cb+dN\n\n\n\n\n\nIn the example in Table Table 2.3, we can calculate the odds of being exposed in the cases as \\(a \\div c\\). Similarly, we can calculate the odds of being exposed in the controls as \\(b \\div d\\). We can the calculate the odds ratio as:\n\\[\n\\begin{aligned}\n\\text{Odds ratio} &= (a \\div c) \\div (b \\div d) \\\\\n&= \\frac{a \\times d}{b \\times c} \\\\\n&= \\frac{ad}{bc}\n\\end{aligned}\n\\]\nNote that some authors say we should think of the odds ratio being based on the odds of being a case in the exposed group compared to the odds of being a case in the unexposed group. Here, the exposed group comprises cells “a” and “b”, so the odds of being a case in the exposed group is (a/b). Similarly, for the unexposed group, the odds of being exposed is (c/d). So our odds ratio becomes (a/b) / (c/d). If we rearrange this, we get the same odds ratio as above: (ad)/(bc).\nThe interpretation of an odds ratio is discussed in detail in PHCM9794: Foundations of Epidemiology, and an excerpt is presented here: The meaning of the calculated odds ratio as a measure of association between exposure and outcome is the same as for the rate ratio (relative risk) where:\n\nAn odds ratio &gt;1 indicates that exposure is positively associated with disease (i.e. the exposure may be a cause of disease);\nAn odds ratio &lt; 1 indicates that exposure is negatively associated with disease (i.e. the exposure may be protective against disease); and\nAn odds ratio = 1 indicates no association between the exposure and the outcome.\n\nIn some situations, related to how well controls are recruited into this study, the odds ratio is a close approximation of the relative risk. Therefore, you may see in some published papers of case control studies the OR interpreted as you would interpret a RR. This should be avoided in this course.\nMore information about the problems of interpreting odds-ratios as relative risks has been presented by Deeks (1998) and Schmidt and Kohlmann (2008).\n\n2.6.1 Worked Example 6.4\nA randomised controlled trial was conducted among a group of patients to estimate the side effects of a drug. Fifty patients were randomly allocated to receive the active drug and 50 patients were allocated to receive a placebo drug. The outcome measured was the experience of nausea. The data is given in the files mod06_nausea.dta and mod06_nausea.rds.\nA summary table can be constructed as in Table 2.4.\n\n\n\n\nTable 2.4:  Nausea status by drug exposure \n\n NauseaNo nauseaTotal\n\nActive drug153550\n\nPlacebo44650\n\nTotal1981100\n\n\n\n\n\nWe can use Stata or R to calculate the relative risk (RR=3.75) and its 95% confidence interval (1.34 to 10.51). This tells us that nausea is 3.75 times more likely to occur in the active drug group compared with the placebo group. Because this is a randomised controlled trial, the relative risk would be an appropriate measure of association.\nWe can confirm the estimated relative risk:\n\\[\n\\begin{aligned}\n\\text{RR} &= \\frac{a / (a+b)}{c / (c+d)} \\\\\n  &= \\frac{15 / (15+35)}{4 / (4+46)} \\\\\n  &= \\frac{0.3}{0.08} \\\\\n  &= 3.75\n\\end{aligned}\n\\]\n\n\n2.6.2 Worked Example 6.5\nA case-control study investigated the association between human papillomavirus and oropharyngeal cancer (D'Souza, et al. NEJM 2007), and the results appear in Table 2.5.\n\n\n\n\nTable 2.5:  Association between human papillomavirus and oropharyngeal cancer \n\n CasesControlsTotal\n\n(Oropharyngeal cancer)(No oropharyngeal cancer)\n\nHPV Positive571471\n\nHPV Negative43186229\n\nTotal100200300\n\n\n\n\n\nThe odds ratio is the odds of being HPV positive in cases (those with oropharyngeal cancer) compared to the odds of being HPV positive in the controls (those without oropharyngeal cancer):\n\\[\n\\begin{aligned}\n\\text{OR} &= \\frac{a / c}{b /d} \\\\\n  &= \\frac{57 / 43}{14 / 186} \\\\\n  &= 17.6\n\\end{aligned}\n\\]\nWe can use Stata or R to estimate the odds ratio and its 95% confidence interval. We should use the Cornfield option in Stata to provide a better estimate of the 95% confidence interval. It appears that the jmv package in R does not use the Cornfield approximation to estimate the 95% confidence interval, but uses the Woolf method.\nThe odds ratio is estimated as 17.6, and its 95% confidence interval is estimated 9.0 to 34.3 (Cornfield, using Stata) or 9.0 to 34.5 (Woolf, using R).\nThe interpretation of the confidence intervals for both the relative risk and the odds ratio is the same as for the confidence intervals around other summary measures in that it shows the region in which we are 95% confident that the true population estimate lies."
  },
  {
    "objectID": "06-proportions.html#confidence-intervals-for-proportions",
    "href": "06-proportions.html#confidence-intervals-for-proportions",
    "title": "2  Summary statistics for binary data",
    "section": "2.7 95% confidence intervals for proportions",
    "text": "2.7 95% confidence intervals for proportions\nTo compute the 95% confidence interval for proportions, go to Statistics &gt; Summaries, tables, and tests &gt; Summary and descriptive statistics &gt;Proportion CI calculator. In the cii dialog box as shown below, key in 215 as the Sample size and 47 as the number of Successes. Choose Wald for the normal approximation to binomial distribution CI [Command: cii 215 47, wald] or Wilson for Wilson CI [Command: cii 215 47, wilson].\n\n\n\n\n\n\nStata Output: 95% confidence interval (Wald method)\n\n. cii proportions 215 47, wald\n\n                                                         -- Binomial Wald ---\n    Variable |        Obs  Proportion    Std. Err.       [95% Conf. Interval]\n-------------+---------------------------------------------------------------\n             |        215    .2186047    .0281868        .1633595    .2738498\n\n\n\nStata Output: 95% confidence interval (Wilson method)\n\n. cii proportions 215 47, wilson\n\n                                                         ------ Wilson ------\n    Variable |        Obs  Proportion    Std. Err.       [95% Conf. Interval]\n-------------+---------------------------------------------------------------\n             |        215    .2186047    .0281868        .1685637    .2785246"
  },
  {
    "objectID": "06-proportions.html#significance-test-for-single-proportion",
    "href": "06-proportions.html#significance-test-for-single-proportion",
    "title": "2  Summary statistics for binary data",
    "section": "2.8 Significance test for single proportion",
    "text": "2.8 Significance test for single proportion\nTo perform a binomial test using the data from mod06_smoking_status.dta, it is a good idea to check that the variable is dichotomous and numerically coded in 0 and 1 by using the codebook command. [Command: codebook smoking_status]\n\n. codebook smoking_status \n\n--------------------------------------------------------------------------------\nsmoking_status                                                    Smoking status\n--------------------------------------------------------------------------------\n\n                  type:  numeric (double)\n                 label:  smoking_status\n\n                 range:  [0,1]                        units:  1\n         unique values:  2                        missing .:  0/300\n\n            tabulation:  Freq.   Numeric  Label\n                           246         0  Non-smokers\n                            54         1  Smokers\n\nAfter checking the data, perform the binomial probability test by going to Statistics &gt; Summaries, tables, and tests &gt; Classical tests of hypotheses &gt; Binomial probability test. Select Smoking_status as the Binomial variable. The probability we want to test against is entered in the Probability of success box. To test that the sample proportion (0.18) is different from the population proportion of 0.2, we enter 0.2 as the Probability of success.\n\n\n\n\n\nClick OK or Submit to obtain the following output:\n\n. bitest smoking_status == 0.2\n\n    Variable |        N   Observed k   Expected k   Assumed p   Observed p\n-------------+------------------------------------------------------------\nsmoking_st~s |      300         54           60       0.20000      0.18000\n\n  Pr(k &gt;= 54)            = 0.825531  (one-sided test)\n  Pr(k &lt;= 54)            = 0.215202  (one-sided test)\n  Pr(k &lt;= 54 or k &gt;= 66) = 0.427280  (two-sided test)\n\nA similar process can be used to conduct a z-test for a single proportion, by choosing Statistics &gt; Summaries, tables, and tests &gt; Classical tests of hypotheses &gt; Proportion test:\n\n\n\n\n\n\n. prtest smoking_status == 0.2\n\nOne-sample test of proportion                   Number of obs      =       300\n\n------------------------------------------------------------------------------\n    Variable |       Mean   Std. Err.                     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\nsmoking_st~s |        .18   .0221811                      .1365259    .2234741\n------------------------------------------------------------------------------\n    p = proportion(smoking_st~s)                                  z =  -0.8660\nHo: p = 0.2\n\n     Ha: p &lt; 0.2                 Ha: p != 0.2                   Ha: p &gt; 0.2\n Pr(Z &lt; z) = 0.1932         Pr(|Z| &gt; |z|) = 0.3865          Pr(Z &gt; z) = 0.8068\n\nIf you have only the aggregate data then the binomial test can be carried out using the immediate command. For that you will need to go through perform the binomial probability test by going to Statistics &gt; Summaries, tables, and tests &gt; Classical tests of hypotheses &gt; Binomial probability test calculator. Enter the numbers in the appropriate fields as shown below.\n\n\n\n\n\n[Command: bitesti 300 54 0.2]"
  },
  {
    "objectID": "06-proportions.html#computing-a-relative-risk-and-its-95-confidence-interval",
    "href": "06-proportions.html#computing-a-relative-risk-and-its-95-confidence-interval",
    "title": "2  Summary statistics for binary data",
    "section": "2.9 Computing a relative risk and its 95% confidence interval",
    "text": "2.9 Computing a relative risk and its 95% confidence interval\nUsing the data file from Worked Example 6.4, to obtain relative risk and its 95% CI, go to Statistics &gt; Epidemiology and related &gt; Tables for epidemiologists &gt; Cohort study risk ratio etc…\n\n\n\n\n\nIn the cs – cohort studies dialog box, select the variable side_effect in the Case variable box, and the variable group in the Exposed variable box.\n\n\n\n\n\nClick OK or Submit to obtain the following output:\n\n                 | Group                  |\n                 |   Exposed   Unexposed  |      Total\n-----------------+------------------------+------------\n           Cases |        15           4  |         19\n        Noncases |        35          46  |         81\n-----------------+------------------------+------------\n           Total |        50          50  |        100\n                 |                        |\n            Risk |        .3         .08  |        .19\n                 |                        |\n                 |      Point estimate    |    [95% Conf. Interval]\n                 |------------------------+------------------------\n Risk difference |              .22       |    .0723899    .3676101 \n      Risk ratio |             3.75       |     1.33754     10.5137 \n Attr. frac. ex. |         .7333333       |    .2523589     .904886 \n Attr. frac. pop |         .5789474       |\n                 +-------------------------------------------------\n                               chi2(1) =     7.86  Pr&gt;chi2 = 0.0050\n\n[Command: cs side_effect group]\nIf you only have the cross-tabulated data (i.e. aggregated), you can go to Statistics &gt; Epidemiology and related &gt; Tables for epidemiologists &gt; Cohort study risk ratio etc. calculator. In the csi dialog box, key in the relevant numbers from the cross-tabulated data (similarly to the cci dialog box above). Click OK or Submit to obtain identical output.\n\n\n\n\n\n[Command: csi 15 4 35 46]"
  },
  {
    "objectID": "06-proportions.html#computing-an-odds-ratio-and-its-95ci",
    "href": "06-proportions.html#computing-an-odds-ratio-and-its-95ci",
    "title": "2  Summary statistics for binary data",
    "section": "2.10 Computing an odds ratio and its 95%CI",
    "text": "2.10 Computing an odds ratio and its 95%CI\nTo obtain an odds ratio and its 95% CI, go to Statistics &gt; Epidemiology and related &gt; Tables for epidemiologists &gt; Case-control odds ratio. The cc dialog box is completed as for the cs dialog box.\nTo obtain the Cornfield confidence interval, click on the Options tab and select the Cornfield approximation radio button.\n\n\n\n\n\n\n                                                         Proportion\n                 |   Exposed   Unexposed  |      Total      exposed\n-----------------+------------------------+------------------------\n           Cases |        57          43  |        100       0.5700\n        Controls |        14         186  |        200       0.0700\n-----------------+------------------------+------------------------\n           Total |        71         229  |        300       0.2367\n                 |                        |\n                 |      Point estimate    |    [95% Conf. Interval]\n                 |------------------------+------------------------\n      Odds ratio |          17.6113       |    9.043258    34.25468 (Cornfield)\n Attr. frac. ex. |         .9432183       |    .8894204    .9708069 (Cornfield)\n Attr. frac. pop |         .5376344       |\n                 +-------------------------------------------------\n                               chi2(1) =    92.26  Pr&gt;chi2 = 0.0000\n\nIf you only have the cross-tabulated data (i.e. aggregated), you can go to Statistics &gt; Epidemiology and related &gt; Tables for epidemiologists &gt; Case-control odds ratio calculator. In the cci dialog box, enter the numbers from the cross-tabulated data and select the Cornfield approximation radio button. For example, Worked example 6.5 would be entered as:"
  },
  {
    "objectID": "06-proportions.html#confidence-intervals-for-proportions-1",
    "href": "06-proportions.html#confidence-intervals-for-proportions-1",
    "title": "2  Summary statistics for binary data",
    "section": "2.11 95% confidence intervals for proportions",
    "text": "2.11 95% confidence intervals for proportions\nWe can use the BinomCI(x=, n=, method=) function within the DescTools package to compute 95% confidence intervals for proportions. Here we specify x: the number of successes, n: the sample size, and optionally, the method (which defaults to Wilson’s method).\n\nlibrary(DescTools)\n\nBinomCI(x=47, n=215, method='wald')\n\n           est    lwr.ci    upr.ci\n[1,] 0.2186047 0.1633595 0.2738498\n\nBinomCI(x=47, n=215, method='wilson')\n\n           est    lwr.ci    upr.ci\n[1,] 0.2186047 0.1685637 0.2785246"
  },
  {
    "objectID": "06-proportions.html#significance-test-for-single-proportion-1",
    "href": "06-proportions.html#significance-test-for-single-proportion-1",
    "title": "2  Summary statistics for binary data",
    "section": "2.12 Significance test for single proportion",
    "text": "2.12 Significance test for single proportion\nWe can use the binom.test function to perform a significance test for a single proportion: binom.test(x=, n=, p=). Here we specify x: the number of successes, n: the sample size, and p: the hypothesised proportion (which defaults to 0.5 if nothing is entered).\n\nbinom.test(x=54, n=300, p=0.2)\n\n\n    Exact binomial test\n\ndata:  54 and 300\nnumber of successes = 54, number of trials = 300, p-value = 0.4273\nalternative hypothesis: true probability of success is not equal to 0.2\n95 percent confidence interval:\n 0.1382104 0.2282394\nsample estimates:\nprobability of success \n                  0.18 \n\n\nNote that the binom.test function also produces a 95% confidence interval around the estimated proportion. This confidence interval is based on the inferior Wald method: the confidence interval derived from the Wilson method is preferred.\nWe can also conduct a z-test for a single proportion:\n\nprop.test(x=54, n=300, p=0.2, correct=FALSE)\n\n\n    1-sample proportions test without continuity correction\n\ndata:  54 out of 300, null probability 0.2\nX-squared = 0.75, df = 1, p-value = 0.3865\nalternative hypothesis: true p is not equal to 0.2\n95 percent confidence interval:\n 0.1406583 0.2274332\nsample estimates:\n   p \n0.18"
  },
  {
    "objectID": "06-proportions.html#computing-a-relative-risk-and-its-95-confidence-interval-1",
    "href": "06-proportions.html#computing-a-relative-risk-and-its-95-confidence-interval-1",
    "title": "2  Summary statistics for binary data",
    "section": "2.13 Computing a relative risk and its 95% confidence interval",
    "text": "2.13 Computing a relative risk and its 95% confidence interval\nWe will use Worked Example 6.4 to demonstrate calculating a relative risk and its 95% CI:\n\nlibrary(jmv)\n\ndrug &lt;- readRDS(\"data/examples/mod06_nausea.rds\")\n\nsummary(drug)\n\n     group       side_effect\n Placebo:50   No nausea:81  \n Active :50   Nausea   :19  \n\n\nBy using the head() function to view the first six lines of data, we see that both group and side_effect have been entered as factors. Notice the order in which the factor levels are presented: group has the Placebo level defined as the first level, and the Active level defined as the second; side_effect has No nausea defined as the first level, and the Nausea level defined as the second.\nWe will use jmv to calculate relative risks, odds ratios and risk differences. To calculate these estimates correctly, we must define the positive exposure and positive outcome to be the first level of a factor. When defining an exposure for example, we should define the active treatment or the positive exposure as the first category. When defining an outcome, we should define the category of interest (e.g. disease, or side effect) as the first category.\nIn this example, we will define Active as the first level in the group factor, and Nausea to be the first level of the side_effect factor.\nWe can do this using the relevel() function, which re-orders the levels of a factor so that the level specified is defined as the first level, and the others are moved down:\n\n# Define \"Active\" as the first level of group:\ndrug$group &lt;- relevel(drug$group, ref=\"Active\")\n\n\n# Define \"Nausea\" as the first level of side_effect:\ndrug$side_effect &lt;- relevel(drug$side_effect, ref=\"Nausea\")\n\nUpon re-leveling the factors, we can check that the levels of interest have been defined as the first levels:\n\nsummary(drug)\n\n     group       side_effect\n Active :50   Nausea   :19  \n Placebo:50   No nausea:81  \n\n\nTo construct the 2-by-2 table and calculate a relative risk, we use the contTables() function in jmv. We request the row-percents using pcRow = TRUE and the relative risk and confidence interval using relRisk = TRUE:\n\ncontTables(data=drug, \n           rows=group, cols=side_effect, \n           pcRow=TRUE, relRisk = TRUE)\n\n\n CONTINGENCY TABLES\n\n Contingency Tables                                                 \n ────────────────────────────────────────────────────────────────── \n   group                      Nausea       No nausea    Total       \n ────────────────────────────────────────────────────────────────── \n   Active     Observed               15           35           50   \n              % within row     30.00000     70.00000    100.00000   \n                                                                    \n   Placebo    Observed                4           46           50   \n              % within row      8.00000     92.00000    100.00000   \n                                                                    \n   Total      Observed               19           81          100   \n              % within row     19.00000     81.00000    100.00000   \n ────────────────────────────────────────────────────────────────── \n\n\n χ² Tests                              \n ───────────────────────────────────── \n         Value       df    p           \n ───────────────────────────────────── \n   χ²    7.862248     1    0.0050478   \n   N          100                      \n ───────────────────────────────────── \n\n\n Comparative Measures                                    \n ─────────────────────────────────────────────────────── \n                    Value         Lower       Upper      \n ─────────────────────────────────────────────────────── \n   Relative risk    3.750000 ᵃ    1.337540    10.51370   \n ─────────────────────────────────────────────────────── \n   ᵃ Rows compared\n\n\nIf you only have the cross-tabulated data (i.e. aggregated), you will need to enter your data into a new data frame. For example, to recreate the above analyses, we can re-write the 2-by-2 table as follows:\n\n\n\nGroup\nside_effect\nNumber\n\n\n\n\nActive\nNausea\n15\n\n\nActive\nNo nausea\n35\n\n\nPlacebo\nNausea\n4\n\n\nPlacebo\nNo nausea\n46\n\n\n\nWe can enter these data in a dataframe, comprising three vectors, as follows:\n\ndrug_aggregated &lt;- data.frame(\n  group = c(\"Active\", \"Active\", \"Placebo\", \"Placebo\"),\n  side_effect = c(\"Nausea\", \"No nausea\", \"Nausea\", \"No nausea\"),\n  n = c(15, 35, 4, 46)\n)\n\nWe need to define group and side_effect as factors. Here we must define the levels in the order we want the categories to appear in the table. Note that as group and side_effect are entered as text variables, we can omit labels command when defining the factors, and the factor will be labelled using the text entry:\n\ndrug_aggregated$group &lt;- factor(drug_aggregated$group, \n                                levels=c(\"Active\", \"Placebo\"))\n\ndrug_aggregated$side_effect &lt;- factor(drug_aggregated$side_effect, \n                                      levels=c(\"Nausea\", \"No nausea\"))\n\nWe can calculate the relative risk using the summarised data in the same was done previously. However, we need to include the number of observations in each cell using the counts command:\n\ncontTables(data=drug_aggregated,\n           rows=group, cols=side_effect, count=n,\n           pcRow=TRUE, relRisk = TRUE)\n\n\n CONTINGENCY TABLES\n\n Contingency Tables                                                 \n ────────────────────────────────────────────────────────────────── \n   group                      Nausea       No nausea    Total       \n ────────────────────────────────────────────────────────────────── \n   Active     Observed               15           35           50   \n              % within row     30.00000     70.00000    100.00000   \n                                                                    \n   Placebo    Observed                4           46           50   \n              % within row      8.00000     92.00000    100.00000   \n                                                                    \n   Total      Observed               19           81          100   \n              % within row     19.00000     81.00000    100.00000   \n ────────────────────────────────────────────────────────────────── \n\n\n χ² Tests                              \n ───────────────────────────────────── \n         Value       df    p           \n ───────────────────────────────────── \n   χ²    7.862248     1    0.0050478   \n   N          100                      \n ───────────────────────────────────── \n\n\n Comparative Measures                                    \n ─────────────────────────────────────────────────────── \n                    Value         Lower       Upper      \n ─────────────────────────────────────────────────────── \n   Relative risk    3.750000 ᵃ    1.337540    10.51370   \n ─────────────────────────────────────────────────────── \n   ᵃ Rows compared"
  },
  {
    "objectID": "06-proportions.html#computing-a-difference-in-proportions-and-its-95-confidence-interval",
    "href": "06-proportions.html#computing-a-difference-in-proportions-and-its-95-confidence-interval",
    "title": "2  Summary statistics for binary data",
    "section": "2.14 Computing a difference in proportions and its 95% confidence interval",
    "text": "2.14 Computing a difference in proportions and its 95% confidence interval\nWe can use the contTables function to obtain a difference in proportions and its 95% CI, by specifying diffProp=TRUE:\n\ncontTables(data=drug, \n           rows=group, cols=side_effect, \n           pcRow=TRUE, diffProp=TRUE)\n\n\n CONTINGENCY TABLES\n\n Contingency Tables                                                 \n ────────────────────────────────────────────────────────────────── \n   group                      Nausea       No nausea    Total       \n ────────────────────────────────────────────────────────────────── \n   Active     Observed               15           35           50   \n              % within row     30.00000     70.00000    100.00000   \n                                                                    \n   Placebo    Observed                4           46           50   \n              % within row      8.00000     92.00000    100.00000   \n                                                                    \n   Total      Observed               19           81          100   \n              % within row     19.00000     81.00000    100.00000   \n ────────────────────────────────────────────────────────────────── \n\n\n χ² Tests                              \n ───────────────────────────────────── \n         Value       df    p           \n ───────────────────────────────────── \n   χ²    7.862248     1    0.0050478   \n   N          100                      \n ───────────────────────────────────── \n\n\n Comparative Measures                                                      \n ───────────────────────────────────────────────────────────────────────── \n                                  Value          Lower         Upper       \n ───────────────────────────────────────────────────────────────────────── \n   Difference in 2 proportions    0.2200000 ᵃ    0.07238986    0.3676101   \n ───────────────────────────────────────────────────────────────────────── \n   ᵃ Rows compared"
  },
  {
    "objectID": "06-proportions.html#computing-an-odds-ratio-and-its-95-confidence-interval",
    "href": "06-proportions.html#computing-an-odds-ratio-and-its-95-confidence-interval",
    "title": "2  Summary statistics for binary data",
    "section": "2.15 Computing an odds ratio and its 95% confidence interval",
    "text": "2.15 Computing an odds ratio and its 95% confidence interval\nWe can use the contTables function to obtain an odds ratio and its 95% CI, by specifying odds=TRUE. Here we will use the summarised HPV data from Module 6.\n\nhpv &lt;- data.frame(\n  hpv = c(\"HPV +\", \"HPV +\", \"HPV -\", \"HPV -\"),\n  cancer = c(\"Case\", \"Control\", \"Case\", \"Control\"),\n  n = c(57, 14, 43, 186)\n)\n\nhpv$cancer &lt;- factor(hpv$cancer, levels=c(\"Case\", \"Control\"))\nhpv$hpv &lt;- factor(hpv$hpv, levels=c(\"HPV +\", \"HPV -\"))\n\ncontTables(data=hpv, \n           rows=hpv, cols=cancer, count=n,\n           odds = TRUE)\n\n\n CONTINGENCY TABLES\n\n Contingency Tables                    \n ───────────────────────────────────── \n   hpv      Case    Control    Total   \n ───────────────────────────────────── \n   HPV +      57         14       71   \n   HPV -      43        186      229   \n   Total     100        200      300   \n ───────────────────────────────────── \n\n\n χ² Tests                               \n ────────────────────────────────────── \n         Value       df    p            \n ────────────────────────────────────── \n   χ²    92.25660     1    &lt; .0000001   \n   N          300                       \n ────────────────────────────────────── \n\n\n Comparative Measures                               \n ────────────────────────────────────────────────── \n                 Value       Lower       Upper      \n ────────────────────────────────────────────────── \n   Odds ratio    17.61130    8.992580    34.49041   \n ────────────────────────────────────────────────── \n\n\nNote that 95% confidence intervals for the odds ratio based on jmv differ from those calculated by Stata. It appears that jmv uses the Woolf method to calculate confidence intervals, but this is not documented."
  },
  {
    "objectID": "98.1-appendix1.html",
    "href": "98.1-appendix1.html",
    "title": "Appendix",
    "section": "",
    "text": "Analysis flowchart"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Acock, Alan C. 2010. A Gentle Introduction to\nStata. 3rd ed. College Station, Tex: Stata Press.\n\n\nBland, Martin. 2015. An Introduction to Medical\nStatistics. 4th Edition. Oxford, New York: Oxford University\nPress.\n\n\nBrown, Lawrence D., T. Tony Cai, and Anirban DasGupta. 2001.\n“Interval Estimation for a Binomial\nProportion.” Statistical Science 16 (2): 101–17.\nhttps://www.jstor.org/stable/2676784.\n\n\nDeeks, Jon. 1998. “When Can Odds Ratios Mislead?”\nBMJ 317 (7166): 1155. https://doi.org/10.1136/bmj.317.7166.1155a.\n\n\nKirkwood, Betty, and Jonathan Sterne. 2001. Essentials of\nMedical Statistics. 2nd edition. Malden, Mass:\nWiley-Blackwell.\n\n\nSchmidt, Carsten Oliver, and Thomas Kohlmann. 2008. “When to Use\nthe Odds Ratio or the Relative Risk?” International Journal\nof Public Health 53 (3): 165–67. https://doi.org/10.1007/s00038-008-7068-3.\n\n\nWebb, Penny, Chris Bain, and Andrew Page. 2016. Essential\nEpidemiology: An Introduction for\nStudents and Health Professionals. 3rd\nedition. Cambridge: Cambridge University Press."
  }
]